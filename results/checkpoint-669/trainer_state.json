{
  "best_global_step": 669,
  "best_metric": 0.8273700475692749,
  "best_model_checkpoint": "./results/checkpoint-669",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 669,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04484304932735426,
      "grad_norm": 113.55934143066406,
      "learning_rate": 9.943946188340807e-05,
      "loss": 11.7056,
      "step": 10
    },
    {
      "epoch": 0.08968609865470852,
      "grad_norm": 1.6162296533584595,
      "learning_rate": 9.831838565022421e-05,
      "loss": 0.7801,
      "step": 20
    },
    {
      "epoch": 0.13452914798206278,
      "grad_norm": 0.8721603751182556,
      "learning_rate": 9.719730941704035e-05,
      "loss": 0.6564,
      "step": 30
    },
    {
      "epoch": 0.17937219730941703,
      "grad_norm": 0.6791540384292603,
      "learning_rate": 9.607623318385651e-05,
      "loss": 0.5308,
      "step": 40
    },
    {
      "epoch": 0.2242152466367713,
      "grad_norm": 0.6984023451805115,
      "learning_rate": 9.495515695067265e-05,
      "loss": 0.3642,
      "step": 50
    },
    {
      "epoch": 0.26905829596412556,
      "grad_norm": 0.47805285453796387,
      "learning_rate": 9.383408071748879e-05,
      "loss": 0.438,
      "step": 60
    },
    {
      "epoch": 0.31390134529147984,
      "grad_norm": 1.4074922800064087,
      "learning_rate": 9.271300448430493e-05,
      "loss": 0.4291,
      "step": 70
    },
    {
      "epoch": 0.35874439461883406,
      "grad_norm": 0.728446364402771,
      "learning_rate": 9.159192825112108e-05,
      "loss": 0.3699,
      "step": 80
    },
    {
      "epoch": 0.40358744394618834,
      "grad_norm": 0.8075895309448242,
      "learning_rate": 9.047085201793722e-05,
      "loss": 0.35,
      "step": 90
    },
    {
      "epoch": 0.4484304932735426,
      "grad_norm": 1.5687953233718872,
      "learning_rate": 8.934977578475336e-05,
      "loss": 0.3654,
      "step": 100
    },
    {
      "epoch": 0.49327354260089684,
      "grad_norm": 0.9762858748435974,
      "learning_rate": 8.822869955156951e-05,
      "loss": 0.3878,
      "step": 110
    },
    {
      "epoch": 0.5381165919282511,
      "grad_norm": 1.153099775314331,
      "learning_rate": 8.710762331838565e-05,
      "loss": 0.238,
      "step": 120
    },
    {
      "epoch": 0.5829596412556054,
      "grad_norm": 0.9977353811264038,
      "learning_rate": 8.59865470852018e-05,
      "loss": 0.3775,
      "step": 130
    },
    {
      "epoch": 0.6278026905829597,
      "grad_norm": 0.6593763828277588,
      "learning_rate": 8.486547085201793e-05,
      "loss": 0.2203,
      "step": 140
    },
    {
      "epoch": 0.672645739910314,
      "grad_norm": 0.7601669430732727,
      "learning_rate": 8.374439461883409e-05,
      "loss": 0.3816,
      "step": 150
    },
    {
      "epoch": 0.7174887892376681,
      "grad_norm": 0.8882759213447571,
      "learning_rate": 8.262331838565023e-05,
      "loss": 0.2639,
      "step": 160
    },
    {
      "epoch": 0.7623318385650224,
      "grad_norm": 1.0117225646972656,
      "learning_rate": 8.150224215246637e-05,
      "loss": 0.2698,
      "step": 170
    },
    {
      "epoch": 0.8071748878923767,
      "grad_norm": 1.8059017658233643,
      "learning_rate": 8.038116591928252e-05,
      "loss": 0.2771,
      "step": 180
    },
    {
      "epoch": 0.852017937219731,
      "grad_norm": 1.2834113836288452,
      "learning_rate": 7.926008968609866e-05,
      "loss": 0.3696,
      "step": 190
    },
    {
      "epoch": 0.8968609865470852,
      "grad_norm": 0.9294933080673218,
      "learning_rate": 7.81390134529148e-05,
      "loss": 0.2521,
      "step": 200
    },
    {
      "epoch": 0.9417040358744395,
      "grad_norm": 1.8745770454406738,
      "learning_rate": 7.701793721973094e-05,
      "loss": 0.2409,
      "step": 210
    },
    {
      "epoch": 0.9865470852017937,
      "grad_norm": 0.9554387331008911,
      "learning_rate": 7.589686098654709e-05,
      "loss": 0.18,
      "step": 220
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8809760212898254,
      "eval_runtime": 7.0713,
      "eval_samples_per_second": 7.919,
      "eval_steps_per_second": 7.919,
      "step": 223
    },
    {
      "epoch": 1.031390134529148,
      "grad_norm": 2.4310553073883057,
      "learning_rate": 7.477578475336323e-05,
      "loss": 0.208,
      "step": 230
    },
    {
      "epoch": 1.0762331838565022,
      "grad_norm": 2.5868661403656006,
      "learning_rate": 7.365470852017937e-05,
      "loss": 0.2847,
      "step": 240
    },
    {
      "epoch": 1.1210762331838564,
      "grad_norm": 0.6030901670455933,
      "learning_rate": 7.253363228699553e-05,
      "loss": 0.189,
      "step": 250
    },
    {
      "epoch": 1.1659192825112108,
      "grad_norm": 0.6657054424285889,
      "learning_rate": 7.141255605381167e-05,
      "loss": 0.2401,
      "step": 260
    },
    {
      "epoch": 1.210762331838565,
      "grad_norm": 1.4416385889053345,
      "learning_rate": 7.02914798206278e-05,
      "loss": 0.2746,
      "step": 270
    },
    {
      "epoch": 1.2556053811659194,
      "grad_norm": 1.1108380556106567,
      "learning_rate": 6.917040358744396e-05,
      "loss": 0.1655,
      "step": 280
    },
    {
      "epoch": 1.3004484304932735,
      "grad_norm": 2.1796648502349854,
      "learning_rate": 6.80493273542601e-05,
      "loss": 0.2867,
      "step": 290
    },
    {
      "epoch": 1.3452914798206277,
      "grad_norm": 0.560278058052063,
      "learning_rate": 6.692825112107624e-05,
      "loss": 0.1498,
      "step": 300
    },
    {
      "epoch": 1.390134529147982,
      "grad_norm": 2.7851104736328125,
      "learning_rate": 6.580717488789238e-05,
      "loss": 0.132,
      "step": 310
    },
    {
      "epoch": 1.4349775784753362,
      "grad_norm": 0.7652709484100342,
      "learning_rate": 6.468609865470853e-05,
      "loss": 0.1932,
      "step": 320
    },
    {
      "epoch": 1.4798206278026906,
      "grad_norm": 1.0700852870941162,
      "learning_rate": 6.356502242152467e-05,
      "loss": 0.1945,
      "step": 330
    },
    {
      "epoch": 1.5246636771300448,
      "grad_norm": 1.9736111164093018,
      "learning_rate": 6.244394618834081e-05,
      "loss": 0.226,
      "step": 340
    },
    {
      "epoch": 1.5695067264573992,
      "grad_norm": 1.186213493347168,
      "learning_rate": 6.132286995515696e-05,
      "loss": 0.1566,
      "step": 350
    },
    {
      "epoch": 1.6143497757847534,
      "grad_norm": 2.794851541519165,
      "learning_rate": 6.02017937219731e-05,
      "loss": 0.2086,
      "step": 360
    },
    {
      "epoch": 1.6591928251121075,
      "grad_norm": 0.9857669472694397,
      "learning_rate": 5.908071748878924e-05,
      "loss": 0.1405,
      "step": 370
    },
    {
      "epoch": 1.704035874439462,
      "grad_norm": 1.9166799783706665,
      "learning_rate": 5.795964125560538e-05,
      "loss": 0.2201,
      "step": 380
    },
    {
      "epoch": 1.7488789237668163,
      "grad_norm": 1.5321910381317139,
      "learning_rate": 5.683856502242153e-05,
      "loss": 0.1379,
      "step": 390
    },
    {
      "epoch": 1.7937219730941703,
      "grad_norm": 1.6374104022979736,
      "learning_rate": 5.571748878923767e-05,
      "loss": 0.1819,
      "step": 400
    },
    {
      "epoch": 1.8385650224215246,
      "grad_norm": 0.5777460336685181,
      "learning_rate": 5.459641255605381e-05,
      "loss": 0.1462,
      "step": 410
    },
    {
      "epoch": 1.883408071748879,
      "grad_norm": 1.440368413925171,
      "learning_rate": 5.3475336322869964e-05,
      "loss": 0.1393,
      "step": 420
    },
    {
      "epoch": 1.9282511210762332,
      "grad_norm": 1.1043734550476074,
      "learning_rate": 5.23542600896861e-05,
      "loss": 0.1588,
      "step": 430
    },
    {
      "epoch": 1.9730941704035874,
      "grad_norm": 0.7080147862434387,
      "learning_rate": 5.123318385650224e-05,
      "loss": 0.2283,
      "step": 440
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8306917548179626,
      "eval_runtime": 7.13,
      "eval_samples_per_second": 7.854,
      "eval_steps_per_second": 7.854,
      "step": 446
    },
    {
      "epoch": 2.0179372197309418,
      "grad_norm": 1.4618682861328125,
      "learning_rate": 5.011210762331838e-05,
      "loss": 0.1779,
      "step": 450
    },
    {
      "epoch": 2.062780269058296,
      "grad_norm": 0.9104284048080444,
      "learning_rate": 4.8991031390134536e-05,
      "loss": 0.1392,
      "step": 460
    },
    {
      "epoch": 2.10762331838565,
      "grad_norm": 0.8053988218307495,
      "learning_rate": 4.7869955156950676e-05,
      "loss": 0.169,
      "step": 470
    },
    {
      "epoch": 2.1524663677130045,
      "grad_norm": 1.066494345664978,
      "learning_rate": 4.674887892376682e-05,
      "loss": 0.1236,
      "step": 480
    },
    {
      "epoch": 2.197309417040359,
      "grad_norm": 0.9483650326728821,
      "learning_rate": 4.562780269058296e-05,
      "loss": 0.1644,
      "step": 490
    },
    {
      "epoch": 2.242152466367713,
      "grad_norm": 1.0516626834869385,
      "learning_rate": 4.450672645739911e-05,
      "loss": 0.1389,
      "step": 500
    },
    {
      "epoch": 2.286995515695067,
      "grad_norm": 0.9088187217712402,
      "learning_rate": 4.338565022421525e-05,
      "loss": 0.1204,
      "step": 510
    },
    {
      "epoch": 2.3318385650224216,
      "grad_norm": 0.6032611131668091,
      "learning_rate": 4.226457399103139e-05,
      "loss": 0.2114,
      "step": 520
    },
    {
      "epoch": 2.376681614349776,
      "grad_norm": 0.7869238257408142,
      "learning_rate": 4.1143497757847535e-05,
      "loss": 0.132,
      "step": 530
    },
    {
      "epoch": 2.42152466367713,
      "grad_norm": 1.698926329612732,
      "learning_rate": 4.0022421524663675e-05,
      "loss": 0.1302,
      "step": 540
    },
    {
      "epoch": 2.4663677130044843,
      "grad_norm": 0.5422634482383728,
      "learning_rate": 3.890134529147982e-05,
      "loss": 0.1149,
      "step": 550
    },
    {
      "epoch": 2.5112107623318387,
      "grad_norm": 2.0443718433380127,
      "learning_rate": 3.778026905829596e-05,
      "loss": 0.1403,
      "step": 560
    },
    {
      "epoch": 2.5560538116591927,
      "grad_norm": 0.7982732057571411,
      "learning_rate": 3.665919282511211e-05,
      "loss": 0.1405,
      "step": 570
    },
    {
      "epoch": 2.600896860986547,
      "grad_norm": 0.9160815477371216,
      "learning_rate": 3.5538116591928255e-05,
      "loss": 0.1521,
      "step": 580
    },
    {
      "epoch": 2.6457399103139014,
      "grad_norm": 0.887535810470581,
      "learning_rate": 3.4417040358744395e-05,
      "loss": 0.1695,
      "step": 590
    },
    {
      "epoch": 2.6905829596412554,
      "grad_norm": 0.8593852519989014,
      "learning_rate": 3.329596412556054e-05,
      "loss": 0.1754,
      "step": 600
    },
    {
      "epoch": 2.7354260089686098,
      "grad_norm": 1.426681637763977,
      "learning_rate": 3.217488789237668e-05,
      "loss": 0.1155,
      "step": 610
    },
    {
      "epoch": 2.780269058295964,
      "grad_norm": 0.6083590984344482,
      "learning_rate": 3.105381165919283e-05,
      "loss": 0.1086,
      "step": 620
    },
    {
      "epoch": 2.8251121076233185,
      "grad_norm": 1.8040636777877808,
      "learning_rate": 2.9932735426008968e-05,
      "loss": 0.1891,
      "step": 630
    },
    {
      "epoch": 2.8699551569506725,
      "grad_norm": 1.014762282371521,
      "learning_rate": 2.8811659192825114e-05,
      "loss": 0.271,
      "step": 640
    },
    {
      "epoch": 2.914798206278027,
      "grad_norm": 0.7253186106681824,
      "learning_rate": 2.7690582959641257e-05,
      "loss": 0.1405,
      "step": 650
    },
    {
      "epoch": 2.9596412556053813,
      "grad_norm": 0.6763383746147156,
      "learning_rate": 2.65695067264574e-05,
      "loss": 0.1643,
      "step": 660
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8273700475692749,
      "eval_runtime": 6.9881,
      "eval_samples_per_second": 8.014,
      "eval_steps_per_second": 8.014,
      "step": 669
    }
  ],
  "logging_steps": 10,
  "max_steps": 892,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2006982498189312.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
