{
  "best_global_step": 154,
  "best_metric": 0.6102594137191772,
  "best_model_checkpoint": "./results/checkpoint-154",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 462,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06493506493506493,
      "grad_norm": Infinity,
      "learning_rate": 9.913419913419914e-05,
      "loss": 12.2303,
      "step": 10
    },
    {
      "epoch": 0.12987012987012986,
      "grad_norm": 1.1999188661575317,
      "learning_rate": 9.71861471861472e-05,
      "loss": 2.0739,
      "step": 20
    },
    {
      "epoch": 0.19480519480519481,
      "grad_norm": 1.0769044160842896,
      "learning_rate": 9.502164502164502e-05,
      "loss": 0.5679,
      "step": 30
    },
    {
      "epoch": 0.2597402597402597,
      "grad_norm": 0.9914402365684509,
      "learning_rate": 9.285714285714286e-05,
      "loss": 0.5001,
      "step": 40
    },
    {
      "epoch": 0.3246753246753247,
      "grad_norm": 1.846235752105713,
      "learning_rate": 9.06926406926407e-05,
      "loss": 0.3488,
      "step": 50
    },
    {
      "epoch": 0.38961038961038963,
      "grad_norm": 0.6159476041793823,
      "learning_rate": 8.852813852813854e-05,
      "loss": 0.4639,
      "step": 60
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.7870704531669617,
      "learning_rate": 8.636363636363637e-05,
      "loss": 0.3549,
      "step": 70
    },
    {
      "epoch": 0.5194805194805194,
      "grad_norm": 0.8814080953598022,
      "learning_rate": 8.41991341991342e-05,
      "loss": 0.3994,
      "step": 80
    },
    {
      "epoch": 0.5844155844155844,
      "grad_norm": 1.6674540042877197,
      "learning_rate": 8.203463203463204e-05,
      "loss": 0.2905,
      "step": 90
    },
    {
      "epoch": 0.6493506493506493,
      "grad_norm": 1.699434518814087,
      "learning_rate": 7.987012987012987e-05,
      "loss": 0.3834,
      "step": 100
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.873725414276123,
      "learning_rate": 7.770562770562771e-05,
      "loss": 0.2432,
      "step": 110
    },
    {
      "epoch": 0.7792207792207793,
      "grad_norm": 0.79930180311203,
      "learning_rate": 7.554112554112555e-05,
      "loss": 0.3066,
      "step": 120
    },
    {
      "epoch": 0.8441558441558441,
      "grad_norm": 0.984978199005127,
      "learning_rate": 7.337662337662338e-05,
      "loss": 0.2044,
      "step": 130
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.7557145357131958,
      "learning_rate": 7.121212121212121e-05,
      "loss": 0.2278,
      "step": 140
    },
    {
      "epoch": 0.974025974025974,
      "grad_norm": 0.7315491437911987,
      "learning_rate": 6.904761904761905e-05,
      "loss": 0.2124,
      "step": 150
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6102594137191772,
      "eval_runtime": 5.0355,
      "eval_samples_per_second": 7.745,
      "eval_steps_per_second": 7.745,
      "step": 154
    },
    {
      "epoch": 1.0389610389610389,
      "grad_norm": 0.8988378047943115,
      "learning_rate": 6.688311688311688e-05,
      "loss": 0.1768,
      "step": 160
    },
    {
      "epoch": 1.103896103896104,
      "grad_norm": 0.9922780394554138,
      "learning_rate": 6.471861471861473e-05,
      "loss": 0.2292,
      "step": 170
    },
    {
      "epoch": 1.1688311688311688,
      "grad_norm": 2.2139954566955566,
      "learning_rate": 6.255411255411255e-05,
      "loss": 0.1866,
      "step": 180
    },
    {
      "epoch": 1.2337662337662338,
      "grad_norm": 0.7446033358573914,
      "learning_rate": 6.03896103896104e-05,
      "loss": 0.1705,
      "step": 190
    },
    {
      "epoch": 1.2987012987012987,
      "grad_norm": 1.003721833229065,
      "learning_rate": 5.822510822510823e-05,
      "loss": 0.151,
      "step": 200
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.8826929330825806,
      "learning_rate": 5.606060606060606e-05,
      "loss": 0.1527,
      "step": 210
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.6995221972465515,
      "learning_rate": 5.38961038961039e-05,
      "loss": 0.1679,
      "step": 220
    },
    {
      "epoch": 1.4935064935064934,
      "grad_norm": 1.3593385219573975,
      "learning_rate": 5.173160173160173e-05,
      "loss": 0.1802,
      "step": 230
    },
    {
      "epoch": 1.5584415584415585,
      "grad_norm": 0.6308301687240601,
      "learning_rate": 4.956709956709957e-05,
      "loss": 0.1246,
      "step": 240
    },
    {
      "epoch": 1.6233766233766234,
      "grad_norm": 0.7584224343299866,
      "learning_rate": 4.740259740259741e-05,
      "loss": 0.1891,
      "step": 250
    },
    {
      "epoch": 1.6883116883116882,
      "grad_norm": 1.6941522359848022,
      "learning_rate": 4.523809523809524e-05,
      "loss": 0.192,
      "step": 260
    },
    {
      "epoch": 1.7532467532467533,
      "grad_norm": 2.016599178314209,
      "learning_rate": 4.3073593073593077e-05,
      "loss": 0.1536,
      "step": 270
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.707263708114624,
      "learning_rate": 4.0909090909090915e-05,
      "loss": 0.1689,
      "step": 280
    },
    {
      "epoch": 1.883116883116883,
      "grad_norm": 0.807266891002655,
      "learning_rate": 3.8744588744588746e-05,
      "loss": 0.1286,
      "step": 290
    },
    {
      "epoch": 1.948051948051948,
      "grad_norm": 0.6368637681007385,
      "learning_rate": 3.6580086580086584e-05,
      "loss": 0.1539,
      "step": 300
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6356779932975769,
      "eval_runtime": 5.2685,
      "eval_samples_per_second": 7.403,
      "eval_steps_per_second": 7.403,
      "step": 308
    },
    {
      "epoch": 2.012987012987013,
      "grad_norm": 0.7893538475036621,
      "learning_rate": 3.4415584415584416e-05,
      "loss": 0.1776,
      "step": 310
    },
    {
      "epoch": 2.0779220779220777,
      "grad_norm": 0.672348141670227,
      "learning_rate": 3.2251082251082254e-05,
      "loss": 0.0951,
      "step": 320
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.9496564269065857,
      "learning_rate": 3.0086580086580092e-05,
      "loss": 0.1664,
      "step": 330
    },
    {
      "epoch": 2.207792207792208,
      "grad_norm": 0.924529492855072,
      "learning_rate": 2.792207792207792e-05,
      "loss": 0.1355,
      "step": 340
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.745755672454834,
      "learning_rate": 2.575757575757576e-05,
      "loss": 0.1118,
      "step": 350
    },
    {
      "epoch": 2.3376623376623376,
      "grad_norm": 0.6526380777359009,
      "learning_rate": 2.3593073593073593e-05,
      "loss": 0.1812,
      "step": 360
    },
    {
      "epoch": 2.4025974025974026,
      "grad_norm": 1.6956167221069336,
      "learning_rate": 2.1428571428571428e-05,
      "loss": 0.1561,
      "step": 370
    },
    {
      "epoch": 2.4675324675324677,
      "grad_norm": 0.5988931655883789,
      "learning_rate": 1.9264069264069266e-05,
      "loss": 0.1027,
      "step": 380
    },
    {
      "epoch": 2.5324675324675323,
      "grad_norm": 0.8186138868331909,
      "learning_rate": 1.70995670995671e-05,
      "loss": 0.17,
      "step": 390
    },
    {
      "epoch": 2.5974025974025974,
      "grad_norm": 1.0048319101333618,
      "learning_rate": 1.4935064935064936e-05,
      "loss": 0.1547,
      "step": 400
    },
    {
      "epoch": 2.6623376623376624,
      "grad_norm": 0.8669492602348328,
      "learning_rate": 1.2770562770562773e-05,
      "loss": 0.0861,
      "step": 410
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.8524917960166931,
      "learning_rate": 1.0606060606060607e-05,
      "loss": 0.1284,
      "step": 420
    },
    {
      "epoch": 2.792207792207792,
      "grad_norm": 0.6167342662811279,
      "learning_rate": 8.441558441558442e-06,
      "loss": 0.1085,
      "step": 430
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 1.006507158279419,
      "learning_rate": 6.277056277056277e-06,
      "loss": 0.1371,
      "step": 440
    },
    {
      "epoch": 2.9220779220779223,
      "grad_norm": 0.7212970852851868,
      "learning_rate": 4.112554112554113e-06,
      "loss": 0.1195,
      "step": 450
    },
    {
      "epoch": 2.987012987012987,
      "grad_norm": 1.138679027557373,
      "learning_rate": 1.948051948051948e-06,
      "loss": 0.1459,
      "step": 460
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6665141582489014,
      "eval_runtime": 5.2037,
      "eval_samples_per_second": 7.495,
      "eval_steps_per_second": 7.495,
      "step": 462
    }
  ],
  "logging_steps": 10,
  "max_steps": 462,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1385987913547776.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
