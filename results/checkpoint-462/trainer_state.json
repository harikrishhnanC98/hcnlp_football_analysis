{
  "best_global_step": 154,
  "best_metric": 11.443120002746582,
  "best_model_checkpoint": "./results/checkpoint-154",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 462,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06493506493506493,
      "grad_norm": NaN,
      "learning_rate": 0.00019696969696969698,
      "loss": 5.9834,
      "step": 10
    },
    {
      "epoch": 0.12987012987012986,
      "grad_norm": 5.951411247253418,
      "learning_rate": 0.00019307359307359307,
      "loss": 1.3345,
      "step": 20
    },
    {
      "epoch": 0.19480519480519481,
      "grad_norm": 1.4674766063690186,
      "learning_rate": 0.00018874458874458875,
      "loss": 0.5621,
      "step": 30
    },
    {
      "epoch": 0.2597402597402597,
      "grad_norm": 1.5094120502471924,
      "learning_rate": 0.00018441558441558442,
      "loss": 0.8262,
      "step": 40
    },
    {
      "epoch": 0.3246753246753247,
      "grad_norm": 0.7035319805145264,
      "learning_rate": 0.0001800865800865801,
      "loss": 0.687,
      "step": 50
    },
    {
      "epoch": 0.38961038961038963,
      "grad_norm": 0.4633062481880188,
      "learning_rate": 0.00017575757575757578,
      "loss": 0.4682,
      "step": 60
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.8077560067176819,
      "learning_rate": 0.00017142857142857143,
      "loss": 0.3273,
      "step": 70
    },
    {
      "epoch": 0.5194805194805194,
      "grad_norm": 1.176979660987854,
      "learning_rate": 0.0001670995670995671,
      "loss": 0.437,
      "step": 80
    },
    {
      "epoch": 0.5844155844155844,
      "grad_norm": 1.8930765390396118,
      "learning_rate": 0.00016277056277056278,
      "loss": 0.3295,
      "step": 90
    },
    {
      "epoch": 0.6493506493506493,
      "grad_norm": 3.976773977279663,
      "learning_rate": 0.00015844155844155845,
      "loss": 0.2905,
      "step": 100
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 1.4761157035827637,
      "learning_rate": 0.00015411255411255413,
      "loss": 0.321,
      "step": 110
    },
    {
      "epoch": 0.7792207792207793,
      "grad_norm": 0.6052296161651611,
      "learning_rate": 0.00014978354978354978,
      "loss": 0.185,
      "step": 120
    },
    {
      "epoch": 0.8441558441558441,
      "grad_norm": 0.503732442855835,
      "learning_rate": 0.00014545454545454546,
      "loss": 0.2108,
      "step": 130
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.4222310781478882,
      "learning_rate": 0.00014112554112554113,
      "loss": 0.2141,
      "step": 140
    },
    {
      "epoch": 0.974025974025974,
      "grad_norm": 0.8826693296432495,
      "learning_rate": 0.0001367965367965368,
      "loss": 0.2267,
      "step": 150
    },
    {
      "epoch": 1.0,
      "eval_loss": 11.443120002746582,
      "eval_runtime": 5.8137,
      "eval_samples_per_second": 6.708,
      "eval_steps_per_second": 6.708,
      "step": 154
    },
    {
      "epoch": 1.0389610389610389,
      "grad_norm": 0.5164802074432373,
      "learning_rate": 0.00013246753246753249,
      "loss": 0.2143,
      "step": 160
    },
    {
      "epoch": 1.103896103896104,
      "grad_norm": 0.4117836356163025,
      "learning_rate": 0.00012813852813852814,
      "loss": 0.1362,
      "step": 170
    },
    {
      "epoch": 1.1688311688311688,
      "grad_norm": 0.44467946887016296,
      "learning_rate": 0.0001238095238095238,
      "loss": 0.1946,
      "step": 180
    },
    {
      "epoch": 1.2337662337662338,
      "grad_norm": 1.8372581005096436,
      "learning_rate": 0.00011948051948051949,
      "loss": 0.2185,
      "step": 190
    },
    {
      "epoch": 1.2987012987012987,
      "grad_norm": 1.0721837282180786,
      "learning_rate": 0.00011515151515151516,
      "loss": 0.1854,
      "step": 200
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.9752598404884338,
      "learning_rate": 0.00011082251082251083,
      "loss": 0.2116,
      "step": 210
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 1.200927972793579,
      "learning_rate": 0.00010649350649350649,
      "loss": 0.2165,
      "step": 220
    },
    {
      "epoch": 1.4935064935064934,
      "grad_norm": 0.5018307566642761,
      "learning_rate": 0.00010216450216450218,
      "loss": 0.184,
      "step": 230
    },
    {
      "epoch": 1.5584415584415585,
      "grad_norm": 0.6038781404495239,
      "learning_rate": 9.783549783549783e-05,
      "loss": 0.1467,
      "step": 240
    },
    {
      "epoch": 1.6233766233766234,
      "grad_norm": 0.5386280417442322,
      "learning_rate": 9.35064935064935e-05,
      "loss": 0.1964,
      "step": 250
    },
    {
      "epoch": 1.6883116883116882,
      "grad_norm": 0.8230112195014954,
      "learning_rate": 8.917748917748918e-05,
      "loss": 0.1964,
      "step": 260
    },
    {
      "epoch": 1.7532467532467533,
      "grad_norm": 0.5474861860275269,
      "learning_rate": 8.484848484848486e-05,
      "loss": 0.1372,
      "step": 270
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.5533515810966492,
      "learning_rate": 8.051948051948052e-05,
      "loss": 0.2175,
      "step": 280
    },
    {
      "epoch": 1.883116883116883,
      "grad_norm": 0.4615219831466675,
      "learning_rate": 7.619047619047618e-05,
      "loss": 0.1675,
      "step": 290
    },
    {
      "epoch": 1.948051948051948,
      "grad_norm": 0.5555883049964905,
      "learning_rate": 7.186147186147186e-05,
      "loss": 0.2233,
      "step": 300
    },
    {
      "epoch": 2.0,
      "eval_loss": 11.593955039978027,
      "eval_runtime": 5.4568,
      "eval_samples_per_second": 7.147,
      "eval_steps_per_second": 7.147,
      "step": 308
    },
    {
      "epoch": 2.012987012987013,
      "grad_norm": 0.6071944236755371,
      "learning_rate": 6.753246753246754e-05,
      "loss": 0.1383,
      "step": 310
    },
    {
      "epoch": 2.0779220779220777,
      "grad_norm": 0.5871797204017639,
      "learning_rate": 6.320346320346321e-05,
      "loss": 0.1458,
      "step": 320
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.5329816937446594,
      "learning_rate": 5.887445887445888e-05,
      "loss": 0.1311,
      "step": 330
    },
    {
      "epoch": 2.207792207792208,
      "grad_norm": 0.3818753957748413,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.139,
      "step": 340
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.5234780311584473,
      "learning_rate": 5.0216450216450216e-05,
      "loss": 0.1719,
      "step": 350
    },
    {
      "epoch": 2.3376623376623376,
      "grad_norm": 0.6276434659957886,
      "learning_rate": 4.588744588744589e-05,
      "loss": 0.167,
      "step": 360
    },
    {
      "epoch": 2.4025974025974026,
      "grad_norm": 0.5346267223358154,
      "learning_rate": 4.155844155844156e-05,
      "loss": 0.1395,
      "step": 370
    },
    {
      "epoch": 2.4675324675324677,
      "grad_norm": 0.6736929416656494,
      "learning_rate": 3.722943722943723e-05,
      "loss": 0.1502,
      "step": 380
    },
    {
      "epoch": 2.5324675324675323,
      "grad_norm": 0.9356243014335632,
      "learning_rate": 3.29004329004329e-05,
      "loss": 0.1854,
      "step": 390
    },
    {
      "epoch": 2.5974025974025974,
      "grad_norm": 0.48754340410232544,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.1331,
      "step": 400
    },
    {
      "epoch": 2.6623376623376624,
      "grad_norm": 0.3295608460903168,
      "learning_rate": 2.4242424242424244e-05,
      "loss": 0.1754,
      "step": 410
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.3127635717391968,
      "learning_rate": 1.9913419913419914e-05,
      "loss": 0.1449,
      "step": 420
    },
    {
      "epoch": 2.792207792207792,
      "grad_norm": 0.577576220035553,
      "learning_rate": 1.5584415584415583e-05,
      "loss": 0.1351,
      "step": 430
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.3561564087867737,
      "learning_rate": 1.1255411255411256e-05,
      "loss": 0.0985,
      "step": 440
    },
    {
      "epoch": 2.9220779220779223,
      "grad_norm": 0.5623632669448853,
      "learning_rate": 6.926406926406927e-06,
      "loss": 0.1254,
      "step": 450
    },
    {
      "epoch": 2.987012987012987,
      "grad_norm": 0.48082149028778076,
      "learning_rate": 2.5974025974025976e-06,
      "loss": 0.1513,
      "step": 460
    },
    {
      "epoch": 3.0,
      "eval_loss": 12.342705726623535,
      "eval_runtime": 5.4192,
      "eval_samples_per_second": 7.197,
      "eval_steps_per_second": 7.197,
      "step": 462
    }
  ],
  "logging_steps": 10,
  "max_steps": 462,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1474640820043776.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
