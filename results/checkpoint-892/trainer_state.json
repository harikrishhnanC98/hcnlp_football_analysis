{
  "best_global_step": 892,
  "best_metric": 0.8012716174125671,
  "best_model_checkpoint": "./results/checkpoint-892",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 892,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04484304932735426,
      "grad_norm": 113.55934143066406,
      "learning_rate": 9.943946188340807e-05,
      "loss": 11.7056,
      "step": 10
    },
    {
      "epoch": 0.08968609865470852,
      "grad_norm": 1.6162296533584595,
      "learning_rate": 9.831838565022421e-05,
      "loss": 0.7801,
      "step": 20
    },
    {
      "epoch": 0.13452914798206278,
      "grad_norm": 0.8721603751182556,
      "learning_rate": 9.719730941704035e-05,
      "loss": 0.6564,
      "step": 30
    },
    {
      "epoch": 0.17937219730941703,
      "grad_norm": 0.6791540384292603,
      "learning_rate": 9.607623318385651e-05,
      "loss": 0.5308,
      "step": 40
    },
    {
      "epoch": 0.2242152466367713,
      "grad_norm": 0.6984023451805115,
      "learning_rate": 9.495515695067265e-05,
      "loss": 0.3642,
      "step": 50
    },
    {
      "epoch": 0.26905829596412556,
      "grad_norm": 0.47805285453796387,
      "learning_rate": 9.383408071748879e-05,
      "loss": 0.438,
      "step": 60
    },
    {
      "epoch": 0.31390134529147984,
      "grad_norm": 1.4074922800064087,
      "learning_rate": 9.271300448430493e-05,
      "loss": 0.4291,
      "step": 70
    },
    {
      "epoch": 0.35874439461883406,
      "grad_norm": 0.728446364402771,
      "learning_rate": 9.159192825112108e-05,
      "loss": 0.3699,
      "step": 80
    },
    {
      "epoch": 0.40358744394618834,
      "grad_norm": 0.8075895309448242,
      "learning_rate": 9.047085201793722e-05,
      "loss": 0.35,
      "step": 90
    },
    {
      "epoch": 0.4484304932735426,
      "grad_norm": 1.5687953233718872,
      "learning_rate": 8.934977578475336e-05,
      "loss": 0.3654,
      "step": 100
    },
    {
      "epoch": 0.49327354260089684,
      "grad_norm": 0.9762858748435974,
      "learning_rate": 8.822869955156951e-05,
      "loss": 0.3878,
      "step": 110
    },
    {
      "epoch": 0.5381165919282511,
      "grad_norm": 1.153099775314331,
      "learning_rate": 8.710762331838565e-05,
      "loss": 0.238,
      "step": 120
    },
    {
      "epoch": 0.5829596412556054,
      "grad_norm": 0.9977353811264038,
      "learning_rate": 8.59865470852018e-05,
      "loss": 0.3775,
      "step": 130
    },
    {
      "epoch": 0.6278026905829597,
      "grad_norm": 0.6593763828277588,
      "learning_rate": 8.486547085201793e-05,
      "loss": 0.2203,
      "step": 140
    },
    {
      "epoch": 0.672645739910314,
      "grad_norm": 0.7601669430732727,
      "learning_rate": 8.374439461883409e-05,
      "loss": 0.3816,
      "step": 150
    },
    {
      "epoch": 0.7174887892376681,
      "grad_norm": 0.8882759213447571,
      "learning_rate": 8.262331838565023e-05,
      "loss": 0.2639,
      "step": 160
    },
    {
      "epoch": 0.7623318385650224,
      "grad_norm": 1.0117225646972656,
      "learning_rate": 8.150224215246637e-05,
      "loss": 0.2698,
      "step": 170
    },
    {
      "epoch": 0.8071748878923767,
      "grad_norm": 1.8059017658233643,
      "learning_rate": 8.038116591928252e-05,
      "loss": 0.2771,
      "step": 180
    },
    {
      "epoch": 0.852017937219731,
      "grad_norm": 1.2834113836288452,
      "learning_rate": 7.926008968609866e-05,
      "loss": 0.3696,
      "step": 190
    },
    {
      "epoch": 0.8968609865470852,
      "grad_norm": 0.9294933080673218,
      "learning_rate": 7.81390134529148e-05,
      "loss": 0.2521,
      "step": 200
    },
    {
      "epoch": 0.9417040358744395,
      "grad_norm": 1.8745770454406738,
      "learning_rate": 7.701793721973094e-05,
      "loss": 0.2409,
      "step": 210
    },
    {
      "epoch": 0.9865470852017937,
      "grad_norm": 0.9554387331008911,
      "learning_rate": 7.589686098654709e-05,
      "loss": 0.18,
      "step": 220
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8809760212898254,
      "eval_runtime": 7.0713,
      "eval_samples_per_second": 7.919,
      "eval_steps_per_second": 7.919,
      "step": 223
    },
    {
      "epoch": 1.031390134529148,
      "grad_norm": 2.4310553073883057,
      "learning_rate": 7.477578475336323e-05,
      "loss": 0.208,
      "step": 230
    },
    {
      "epoch": 1.0762331838565022,
      "grad_norm": 2.5868661403656006,
      "learning_rate": 7.365470852017937e-05,
      "loss": 0.2847,
      "step": 240
    },
    {
      "epoch": 1.1210762331838564,
      "grad_norm": 0.6030901670455933,
      "learning_rate": 7.253363228699553e-05,
      "loss": 0.189,
      "step": 250
    },
    {
      "epoch": 1.1659192825112108,
      "grad_norm": 0.6657054424285889,
      "learning_rate": 7.141255605381167e-05,
      "loss": 0.2401,
      "step": 260
    },
    {
      "epoch": 1.210762331838565,
      "grad_norm": 1.4416385889053345,
      "learning_rate": 7.02914798206278e-05,
      "loss": 0.2746,
      "step": 270
    },
    {
      "epoch": 1.2556053811659194,
      "grad_norm": 1.1108380556106567,
      "learning_rate": 6.917040358744396e-05,
      "loss": 0.1655,
      "step": 280
    },
    {
      "epoch": 1.3004484304932735,
      "grad_norm": 2.1796648502349854,
      "learning_rate": 6.80493273542601e-05,
      "loss": 0.2867,
      "step": 290
    },
    {
      "epoch": 1.3452914798206277,
      "grad_norm": 0.560278058052063,
      "learning_rate": 6.692825112107624e-05,
      "loss": 0.1498,
      "step": 300
    },
    {
      "epoch": 1.390134529147982,
      "grad_norm": 2.7851104736328125,
      "learning_rate": 6.580717488789238e-05,
      "loss": 0.132,
      "step": 310
    },
    {
      "epoch": 1.4349775784753362,
      "grad_norm": 0.7652709484100342,
      "learning_rate": 6.468609865470853e-05,
      "loss": 0.1932,
      "step": 320
    },
    {
      "epoch": 1.4798206278026906,
      "grad_norm": 1.0700852870941162,
      "learning_rate": 6.356502242152467e-05,
      "loss": 0.1945,
      "step": 330
    },
    {
      "epoch": 1.5246636771300448,
      "grad_norm": 1.9736111164093018,
      "learning_rate": 6.244394618834081e-05,
      "loss": 0.226,
      "step": 340
    },
    {
      "epoch": 1.5695067264573992,
      "grad_norm": 1.186213493347168,
      "learning_rate": 6.132286995515696e-05,
      "loss": 0.1566,
      "step": 350
    },
    {
      "epoch": 1.6143497757847534,
      "grad_norm": 2.794851541519165,
      "learning_rate": 6.02017937219731e-05,
      "loss": 0.2086,
      "step": 360
    },
    {
      "epoch": 1.6591928251121075,
      "grad_norm": 0.9857669472694397,
      "learning_rate": 5.908071748878924e-05,
      "loss": 0.1405,
      "step": 370
    },
    {
      "epoch": 1.704035874439462,
      "grad_norm": 1.9166799783706665,
      "learning_rate": 5.795964125560538e-05,
      "loss": 0.2201,
      "step": 380
    },
    {
      "epoch": 1.7488789237668163,
      "grad_norm": 1.5321910381317139,
      "learning_rate": 5.683856502242153e-05,
      "loss": 0.1379,
      "step": 390
    },
    {
      "epoch": 1.7937219730941703,
      "grad_norm": 1.6374104022979736,
      "learning_rate": 5.571748878923767e-05,
      "loss": 0.1819,
      "step": 400
    },
    {
      "epoch": 1.8385650224215246,
      "grad_norm": 0.5777460336685181,
      "learning_rate": 5.459641255605381e-05,
      "loss": 0.1462,
      "step": 410
    },
    {
      "epoch": 1.883408071748879,
      "grad_norm": 1.440368413925171,
      "learning_rate": 5.3475336322869964e-05,
      "loss": 0.1393,
      "step": 420
    },
    {
      "epoch": 1.9282511210762332,
      "grad_norm": 1.1043734550476074,
      "learning_rate": 5.23542600896861e-05,
      "loss": 0.1588,
      "step": 430
    },
    {
      "epoch": 1.9730941704035874,
      "grad_norm": 0.7080147862434387,
      "learning_rate": 5.123318385650224e-05,
      "loss": 0.2283,
      "step": 440
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8306917548179626,
      "eval_runtime": 7.13,
      "eval_samples_per_second": 7.854,
      "eval_steps_per_second": 7.854,
      "step": 446
    },
    {
      "epoch": 2.0179372197309418,
      "grad_norm": 1.4618682861328125,
      "learning_rate": 5.011210762331838e-05,
      "loss": 0.1779,
      "step": 450
    },
    {
      "epoch": 2.062780269058296,
      "grad_norm": 0.9104284048080444,
      "learning_rate": 4.8991031390134536e-05,
      "loss": 0.1392,
      "step": 460
    },
    {
      "epoch": 2.10762331838565,
      "grad_norm": 0.8053988218307495,
      "learning_rate": 4.7869955156950676e-05,
      "loss": 0.169,
      "step": 470
    },
    {
      "epoch": 2.1524663677130045,
      "grad_norm": 1.066494345664978,
      "learning_rate": 4.674887892376682e-05,
      "loss": 0.1236,
      "step": 480
    },
    {
      "epoch": 2.197309417040359,
      "grad_norm": 0.9483650326728821,
      "learning_rate": 4.562780269058296e-05,
      "loss": 0.1644,
      "step": 490
    },
    {
      "epoch": 2.242152466367713,
      "grad_norm": 1.0516626834869385,
      "learning_rate": 4.450672645739911e-05,
      "loss": 0.1389,
      "step": 500
    },
    {
      "epoch": 2.286995515695067,
      "grad_norm": 0.9088187217712402,
      "learning_rate": 4.338565022421525e-05,
      "loss": 0.1204,
      "step": 510
    },
    {
      "epoch": 2.3318385650224216,
      "grad_norm": 0.6032611131668091,
      "learning_rate": 4.226457399103139e-05,
      "loss": 0.2114,
      "step": 520
    },
    {
      "epoch": 2.376681614349776,
      "grad_norm": 0.7869238257408142,
      "learning_rate": 4.1143497757847535e-05,
      "loss": 0.132,
      "step": 530
    },
    {
      "epoch": 2.42152466367713,
      "grad_norm": 1.698926329612732,
      "learning_rate": 4.0022421524663675e-05,
      "loss": 0.1302,
      "step": 540
    },
    {
      "epoch": 2.4663677130044843,
      "grad_norm": 0.5422634482383728,
      "learning_rate": 3.890134529147982e-05,
      "loss": 0.1149,
      "step": 550
    },
    {
      "epoch": 2.5112107623318387,
      "grad_norm": 2.0443718433380127,
      "learning_rate": 3.778026905829596e-05,
      "loss": 0.1403,
      "step": 560
    },
    {
      "epoch": 2.5560538116591927,
      "grad_norm": 0.7982732057571411,
      "learning_rate": 3.665919282511211e-05,
      "loss": 0.1405,
      "step": 570
    },
    {
      "epoch": 2.600896860986547,
      "grad_norm": 0.9160815477371216,
      "learning_rate": 3.5538116591928255e-05,
      "loss": 0.1521,
      "step": 580
    },
    {
      "epoch": 2.6457399103139014,
      "grad_norm": 0.887535810470581,
      "learning_rate": 3.4417040358744395e-05,
      "loss": 0.1695,
      "step": 590
    },
    {
      "epoch": 2.6905829596412554,
      "grad_norm": 0.8593852519989014,
      "learning_rate": 3.329596412556054e-05,
      "loss": 0.1754,
      "step": 600
    },
    {
      "epoch": 2.7354260089686098,
      "grad_norm": 1.426681637763977,
      "learning_rate": 3.217488789237668e-05,
      "loss": 0.1155,
      "step": 610
    },
    {
      "epoch": 2.780269058295964,
      "grad_norm": 0.6083590984344482,
      "learning_rate": 3.105381165919283e-05,
      "loss": 0.1086,
      "step": 620
    },
    {
      "epoch": 2.8251121076233185,
      "grad_norm": 1.8040636777877808,
      "learning_rate": 2.9932735426008968e-05,
      "loss": 0.1891,
      "step": 630
    },
    {
      "epoch": 2.8699551569506725,
      "grad_norm": 1.014762282371521,
      "learning_rate": 2.8811659192825114e-05,
      "loss": 0.271,
      "step": 640
    },
    {
      "epoch": 2.914798206278027,
      "grad_norm": 0.7253186106681824,
      "learning_rate": 2.7690582959641257e-05,
      "loss": 0.1405,
      "step": 650
    },
    {
      "epoch": 2.9596412556053813,
      "grad_norm": 0.6763383746147156,
      "learning_rate": 2.65695067264574e-05,
      "loss": 0.1643,
      "step": 660
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8273700475692749,
      "eval_runtime": 6.9881,
      "eval_samples_per_second": 8.014,
      "eval_steps_per_second": 8.014,
      "step": 669
    },
    {
      "epoch": 3.004484304932735,
      "grad_norm": 0.5710631012916565,
      "learning_rate": 2.5448430493273544e-05,
      "loss": 0.1715,
      "step": 670
    },
    {
      "epoch": 3.0493273542600896,
      "grad_norm": 0.5689212083816528,
      "learning_rate": 2.4327354260089687e-05,
      "loss": 0.0869,
      "step": 680
    },
    {
      "epoch": 3.094170403587444,
      "grad_norm": 0.7570568323135376,
      "learning_rate": 2.320627802690583e-05,
      "loss": 0.103,
      "step": 690
    },
    {
      "epoch": 3.1390134529147984,
      "grad_norm": 0.6544616222381592,
      "learning_rate": 2.2085201793721974e-05,
      "loss": 0.1026,
      "step": 700
    },
    {
      "epoch": 3.1838565022421523,
      "grad_norm": 1.4231297969818115,
      "learning_rate": 2.0964125560538117e-05,
      "loss": 0.1202,
      "step": 710
    },
    {
      "epoch": 3.2286995515695067,
      "grad_norm": 1.1849424839019775,
      "learning_rate": 1.984304932735426e-05,
      "loss": 0.1034,
      "step": 720
    },
    {
      "epoch": 3.273542600896861,
      "grad_norm": 1.0378202199935913,
      "learning_rate": 1.8721973094170407e-05,
      "loss": 0.0998,
      "step": 730
    },
    {
      "epoch": 3.318385650224215,
      "grad_norm": 0.5932897925376892,
      "learning_rate": 1.760089686098655e-05,
      "loss": 0.1681,
      "step": 740
    },
    {
      "epoch": 3.3632286995515694,
      "grad_norm": 0.8223734498023987,
      "learning_rate": 1.6479820627802693e-05,
      "loss": 0.1298,
      "step": 750
    },
    {
      "epoch": 3.408071748878924,
      "grad_norm": 0.5271192193031311,
      "learning_rate": 1.5358744394618836e-05,
      "loss": 0.1627,
      "step": 760
    },
    {
      "epoch": 3.452914798206278,
      "grad_norm": 1.3117417097091675,
      "learning_rate": 1.4237668161434978e-05,
      "loss": 0.1129,
      "step": 770
    },
    {
      "epoch": 3.497757847533632,
      "grad_norm": 1.041934609413147,
      "learning_rate": 1.3116591928251121e-05,
      "loss": 0.1451,
      "step": 780
    },
    {
      "epoch": 3.5426008968609866,
      "grad_norm": 3.9957919120788574,
      "learning_rate": 1.1995515695067266e-05,
      "loss": 0.1684,
      "step": 790
    },
    {
      "epoch": 3.587443946188341,
      "grad_norm": 0.7851685285568237,
      "learning_rate": 1.0874439461883407e-05,
      "loss": 0.1053,
      "step": 800
    },
    {
      "epoch": 3.6322869955156953,
      "grad_norm": 0.9213265776634216,
      "learning_rate": 9.753363228699552e-06,
      "loss": 0.2088,
      "step": 810
    },
    {
      "epoch": 3.6771300448430493,
      "grad_norm": 0.8358412981033325,
      "learning_rate": 8.632286995515696e-06,
      "loss": 0.1138,
      "step": 820
    },
    {
      "epoch": 3.7219730941704037,
      "grad_norm": 0.8737808465957642,
      "learning_rate": 7.511210762331839e-06,
      "loss": 0.1714,
      "step": 830
    },
    {
      "epoch": 3.766816143497758,
      "grad_norm": 0.5968506336212158,
      "learning_rate": 6.390134529147983e-06,
      "loss": 0.1496,
      "step": 840
    },
    {
      "epoch": 3.811659192825112,
      "grad_norm": 0.5842887759208679,
      "learning_rate": 5.269058295964126e-06,
      "loss": 0.1747,
      "step": 850
    },
    {
      "epoch": 3.8565022421524664,
      "grad_norm": 1.040182113647461,
      "learning_rate": 4.147982062780269e-06,
      "loss": 0.1458,
      "step": 860
    },
    {
      "epoch": 3.901345291479821,
      "grad_norm": 1.4727555513381958,
      "learning_rate": 3.026905829596413e-06,
      "loss": 0.1093,
      "step": 870
    },
    {
      "epoch": 3.9461883408071747,
      "grad_norm": 0.5544021129608154,
      "learning_rate": 1.9058295964125561e-06,
      "loss": 0.1229,
      "step": 880
    },
    {
      "epoch": 3.991031390134529,
      "grad_norm": 0.9250631332397461,
      "learning_rate": 7.847533632286996e-07,
      "loss": 0.181,
      "step": 890
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.8012716174125671,
      "eval_runtime": 7.0195,
      "eval_samples_per_second": 7.978,
      "eval_steps_per_second": 7.978,
      "step": 892
    }
  ],
  "logging_steps": 10,
  "max_steps": 892,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2675976664252416.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
