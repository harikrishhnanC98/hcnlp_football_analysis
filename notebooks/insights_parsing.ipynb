{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f241dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301859c7",
   "metadata": {},
   "source": [
    "**Q&A from match reports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb218d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "# Base and data/output directory setup\n",
    "base_dir = os.path.abspath(\"..\")\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "output_dir = os.path.join(base_dir, \"outputs\", \"insights_qa\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Verify data folder exists\n",
    "if not os.path.exists(data_dir):\n",
    "    raise FileNotFoundError(f\"Data folder not found at: {data_dir}\")\n",
    "\n",
    "# Updated prompt with stricter output instruction\n",
    "prompt_template = \"\"\"\n",
    "You are a professional football analyst. Read the following match reports. Your goal is to generate 5 concise and high-quality question-answer pairs based on Argentina's performance in the match.\n",
    "You may refer to the opponent's strategy or events only when it directly relates to Argentina’s tactics, decisions, or key moments.\n",
    "Use concise and clear answers. Output the result as a JSON list with keys 'question' and 'answer'.\n",
    "\n",
    "Instructions:\n",
    "1. Read the match report carefully.\n",
    "2. Identify key moments, strategies, and decisions made by Argentina.\n",
    "3. Formulate questions that are relevant to Argentina's performance.\n",
    "4. Provide clear and concise answers based on the report.\n",
    "5. Ensure that the output is in JSON format with 'question' and 'answer' keys.\n",
    "\n",
    "Match Report:\n",
    "{report_text}\n",
    "\"\"\"\n",
    "\n",
    "def parse_qa_pairs(output):\n",
    "    import json\n",
    "\n",
    "    # 1. Try JSON list\n",
    "    try:\n",
    "        json_start = output.find('[')\n",
    "        json_end = output.rfind(']') + 1\n",
    "        json_data = output[json_start:json_end]\n",
    "        qa_list = json.loads(json_data)\n",
    "        if isinstance(qa_list, list) and all(\"question\" in qa and \"answer\" in qa for qa in qa_list):\n",
    "            return qa_list\n",
    "    except Exception as e:\n",
    "        print(\"JSON parsing failed. Trying fallback:\", str(e))\n",
    "\n",
    "    # 2. Fallback: Numbered Q&A like \"1. What...? - Answer\"\n",
    "    qa_pattern = re.compile(r\"\\d+\\.\\s*(.+?)\\s*[-–]\\s*(.+)\")\n",
    "    matches = qa_pattern.findall(output)\n",
    "    if matches:\n",
    "        return [{\"question\": q.strip(), \"answer\": a.strip()} for q, a in matches]\n",
    "\n",
    "    # 3. Fallback: Many individual JSON objects (not in a list)\n",
    "    qa_json_pattern = re.compile(r'\\{\\s*\"question\":\\s*\".+?\",\\s*\"answer\":\\s*\".+?\"\\s*\\}', re.DOTALL)\n",
    "    matches = qa_json_pattern.findall(output)\n",
    "    try:\n",
    "        return [json.loads(block) for block in matches]\n",
    "    except Exception as e:\n",
    "        print(\"Could not parse individual QA JSON blocks:\", str(e))\n",
    "\n",
    "    return []  # Still nothing matched\n",
    "\n",
    "def generate_qa_from_text(text):\n",
    "    prompt = prompt_template.format(report_text=text)\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", \"llama2\"],\n",
    "            input=prompt.encode('utf-8'),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=120\n",
    "        )\n",
    "        output = result.stdout.decode(\"utf-8\").strip()\n",
    "        print(\"Subprocess output:\", output[:300], \"...\\n\")  # Truncated for brevity\n",
    "        return parse_qa_pairs(output), output\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"Timeout reached while generating response\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during subprocess: {e}\")\n",
    "    return None, None\n",
    "\n",
    "def save_qa_to_csv(qa_pairs, file_path):\n",
    "    with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"question\", \"answer\"])\n",
    "        writer.writeheader()\n",
    "        for qa in qa_pairs:\n",
    "            writer.writerow(qa)\n",
    "\n",
    "# Main loop to process each match folder\n",
    "for folder in os.listdir(data_dir):\n",
    "    match_path = os.path.join(data_dir, folder)\n",
    "    if not os.path.isdir(match_path):\n",
    "        continue\n",
    "\n",
    "    txt_files = [f for f in os.listdir(match_path) if f.endswith(\".txt\")]\n",
    "    if not txt_files:\n",
    "        print(f\"No text files found in {folder}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing match: {folder}\")\n",
    "    for txt_file in txt_files:\n",
    "        txt_file_path = os.path.join(match_path, txt_file)\n",
    "\n",
    "        with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            report_text = f.read()\n",
    "\n",
    "        print(f\"Generating Q&A for file: {txt_file}\")\n",
    "        qa_pairs, raw_output = generate_qa_from_text(report_text)\n",
    "\n",
    "        if qa_pairs:\n",
    "            out_file_name = f\"{folder}_{os.path.splitext(txt_file)[0]}.csv\"\n",
    "            out_path = os.path.join(output_dir, out_file_name)\n",
    "            save_qa_to_csv(qa_pairs, out_path)\n",
    "            print(f\"Saved: {out_path}\")\n",
    "        else:\n",
    "            print(f\"Skipped (no Q&A parsed): {txt_file}\")\n",
    "            # Save raw output to a text file\n",
    "            raw_out_file_name = f\"{folder}_{os.path.splitext(txt_file)[0]}_raw.txt\"\n",
    "            raw_out_path = os.path.join(output_dir, raw_out_file_name)\n",
    "            with open(raw_out_path, \"w\", encoding=\"utf-8\") as raw_out_f:\n",
    "                raw_out_f.write(raw_output)\n",
    "            print(f\"Saved raw output: {raw_out_path}\")\n",
    "\n",
    "print(\"\\nAll processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b59e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\1_Arg_vs_Saudi_G1_Text_report_BBC_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\1_Arg_vs_Saudi_G1_Text_report_BBC.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\1_Arg_vs_Saudi_G1_Text_Report_The_Guardian_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\1_Arg_vs_Saudi_G1_Text_Report_The_Guardian.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\2_Arg_vs_Mex_G2_Text_Report_BBC_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\2_Arg_vs_Mex_G2_Text_Report_BBC.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\2_Arg_vs_Mex_G2_Text_Report_The_Guardian_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\2_Arg_vs_Mex_G2_Text_Report_The_Guardian.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\3_Arg_vs_Pol_G3_Text_Report_BBC_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\3_Arg_vs_Pol_G3_Text_Report_BBC.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\3_Arg_vs_Pol_G3_Text_Report_The_Guardian_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\3_Arg_vs_Pol_G3_Text_Report_The_Guardian.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\4_Arg_vs_Aus_R016_Text_Document_The_Guardian_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\4_Arg_vs_Aus_R016_Text_Document_The_Guardian.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\4_Arg_vs_Aus_R016_Text_Report_The_BBC_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\4_Arg_vs_Aus_R016_Text_Report_The_BBC.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\5_Arg_vs_Ned_QF_Text_Report_BBC_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\5_Arg_vs_Ned_QF_Text_Report_BBC.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\5_Arg_vs_Ned_QF_Text_Report_The_Guardian_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\5_Arg_vs_Ned_QF_Text_Report_The_Guardian.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\6_Arg_vs_Cro_SF_Text_Report_BBC_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\6_Arg_vs_Cro_SF_Text_Report_BBC.json\n",
      "Processing file: d:\\Masters\\hcnlp_project\\outputs\\insights_qa\\6_Arg_vs_Cro_SF_Text_Report_The_Guardian_raw.txt\n",
      "Saved: d:\\Masters\\hcnlp_project\\outputs\\insights_qa_json\\6_Arg_vs_Cro_SF_Text_Report_The_Guardian.json\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Base and data/output directory setup\n",
    "base_dir = os.path.abspath(\"..\")\n",
    "data_dir = os.path.join(base_dir, \"outputs\", \"insights_qa\")\n",
    "output_dir = os.path.join(base_dir, \"outputs\", \"insights_qa_json\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def parse_qa_pairs(text):\n",
    "    # Regular expression to match Q&A pairs with flexible formats\n",
    "    qa_pattern = re.compile(r\"(?:Question|Q(?:uestion)?)?\\s*(\\d*)\\s*[:-]\\s*(.+)\\n(?:Answer|A(?:nswer)?)?\\s*[:-]\\s*(.+)\", re.IGNORECASE)\n",
    "    matches = qa_pattern.findall(text)\n",
    "\n",
    "    qa_pairs = []\n",
    "    for match in matches:\n",
    "        qa_pairs.append({\n",
    "            \"question\": match[1].strip(),\n",
    "            \"answer\": match[2].strip()\n",
    "        })\n",
    "    return qa_pairs\n",
    "\n",
    "def save_qa_to_json(qa_pairs, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(qa_pairs, file, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Main loop to process each raw text file\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if file_name.endswith(\"_raw.txt\"):\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            raw_output = file.read()\n",
    "\n",
    "        qa_pairs = parse_qa_pairs(raw_output)\n",
    "\n",
    "        if qa_pairs:\n",
    "            json_file_name = file_name.replace(\"_raw.txt\", \".json\")\n",
    "            json_file_path = os.path.join(output_dir, json_file_name)\n",
    "            save_qa_to_json(qa_pairs, json_file_path)\n",
    "            print(f\"Saved: {json_file_path}\")\n",
    "        else:\n",
    "            print(f\"Skipped (no Q&A parsed): {file_name}\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
