{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openpyxl in c:\\users\\harig\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\harig\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pass network data for all matches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 1_Arg_vs_Saudi_G1.json from 1_Arg_vs_Saudi_G1\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\pass_data\\1_Arg_vs_Saudi_G1.xlsx\n",
      "\n",
      "Processing: 2_Arg_vs_Mex_G2.json from 2_Arg_vs_Mex_G2\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\pass_data\\2_Arg_vs_Mex_G2.xlsx\n",
      "\n",
      "Processing: 3_Arg_vs_Pol_G3.json from 3_Arg_vs_Pol_G3\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\pass_data\\3_Arg_vs_Pol_G3.xlsx\n",
      "\n",
      "Processing: 4_Arg_vs_Aus_R016.json from 4_Arg_vs_Aus_R016\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\pass_data\\4_Arg_vs_Aus_R016.xlsx\n",
      "\n",
      "Processing: 5_Arg_vs_Ned_QF.json from 5_Arg_vs_Ned_QF\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\pass_data\\5_Arg_vs_Ned_QF.xlsx\n",
      "\n",
      "Processing: 6_Arg_vs_Cro_SF.json from 6_Arg_vs_Cro_SF\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\pass_data\\6_Arg_vs_Cro_SF.xlsx\n",
      "\n",
      "Processing: 7_Arg_vs_Fra_Final.json from 7_Arg_vs_Fra_Final\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\pass_data\\7_Arg_vs_Fra_Final.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Set base paths\n",
    "data_dir = os.path.join(\"..\", \"data\")\n",
    "output_base_dir = os.path.join(\"..\", \"outputs\", \"pass_data\")\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "# Set team to filter\n",
    "target_team = \"Argentina\"\n",
    "\n",
    "# Loop through all folders inside 'data'\n",
    "for folder_name in os.listdir(data_dir):\n",
    "    folder_path = os.path.join(data_dir, folder_name)\n",
    "\n",
    "    # Skip if not a directory\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    # Look for the JSON file inside the folder\n",
    "    json_files = [f for f in os.listdir(folder_path) if f.endswith(\".json\")]\n",
    "    if not json_files:\n",
    "        print(f\"No JSON file found in {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    json_file = json_files[0]  # Assuming each folder has only one .json\n",
    "    json_path = os.path.join(folder_path, json_file)\n",
    "\n",
    "    print(f\"\\nProcessing: {json_file} from {folder_name}\")\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract pass events\n",
    "    pass_events = []\n",
    "    for event in data:\n",
    "        if event.get(\"type\", {}).get(\"name\") == \"Pass\" and event.get(\"team\", {}).get(\"name\") == target_team:\n",
    "            passer = event.get(\"player\", {}).get(\"name\")\n",
    "            recipient = event.get(\"pass\", {}).get(\"recipient\", {}).get(\"name\")\n",
    "            team = event.get(\"team\", {}).get(\"name\")\n",
    "            outcome = event.get(\"pass\", {}).get(\"outcome\", {}).get(\"name\", \"Successful\")\n",
    "            success = outcome == \"Successful\"\n",
    "            location = event.get(\"location\", [None, None])\n",
    "            end_location = event.get(\"pass\", {}).get(\"end_location\", [None, None])\n",
    "\n",
    "            pass_events.append({\n",
    "                \"Passer\": passer,\n",
    "                \"Recipient\": recipient,\n",
    "                \"Team\": team,\n",
    "                \"Pass Success\": success,\n",
    "                \"Start X\": location[0],\n",
    "                \"Start Y\": location[1],\n",
    "                \"End X\": end_location[0],\n",
    "                \"End Y\": end_location[1]\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    passes_df = pd.DataFrame(pass_events)\n",
    "\n",
    "    # Output path (same name as json file, but .xlsx)\n",
    "    output_filename = os.path.splitext(json_file)[0] + \".xlsx\"\n",
    "    output_path = os.path.join(output_base_dir, output_filename)\n",
    "\n",
    "    # Save Excel\n",
    "    passes_df.to_excel(output_path, index=False)\n",
    "    print(f\"Saved to: {os.path.abspath(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Player interactions from all matches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 1_Arg_vs_Saudi_G1.xlsx\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\player_interactions\\1_Arg_vs_Saudi_G1_interactions.xlsx\n",
      "\n",
      "Processing: 2_Arg_vs_Mex_G2.xlsx\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\player_interactions\\2_Arg_vs_Mex_G2_interactions.xlsx\n",
      "\n",
      "Processing: 3_Arg_vs_Pol_G3.xlsx\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\player_interactions\\3_Arg_vs_Pol_G3_interactions.xlsx\n",
      "\n",
      "Processing: 4_Arg_vs_Aus_R016.xlsx\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\player_interactions\\4_Arg_vs_Aus_R016_interactions.xlsx\n",
      "\n",
      "Processing: 5_Arg_vs_Ned_QF.xlsx\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\player_interactions\\5_Arg_vs_Ned_QF_interactions.xlsx\n",
      "\n",
      "Processing: 6_Arg_vs_Cro_SF.xlsx\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\player_interactions\\6_Arg_vs_Cro_SF_interactions.xlsx\n",
      "\n",
      "Processing: 7_Arg_vs_Fra_Final.xlsx\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\player_interactions\\7_Arg_vs_Fra_Final_interactions.xlsx\n",
      "\n",
      "Processing: arg_sau_passes.xlsx\n",
      "Saved to: d:\\Masters\\hcnlp_project\\outputs\\player_interactions\\arg_sau_passes_interactions.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "input_dir = os.path.join(\"..\", \"outputs\", \"pass_data\")\n",
    "output_dir = os.path.join(\"..\", \"outputs\", \"player_interactions\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop over all Excel files in the pass_data folder\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        input_path = os.path.join(input_dir, file)\n",
    "        print(f\"\\nProcessing: {file}\")\n",
    "\n",
    "        # Load the Excel file\n",
    "        df = pd.read_excel(input_path)\n",
    "\n",
    "        # Drop rows with missing passers or recipients\n",
    "        df = df.dropna(subset=[\"Passer\", \"Recipient\"])\n",
    "\n",
    "        # Get unique players\n",
    "        players = sorted(set(df[\"Passer\"]).union(set(df[\"Recipient\"])))\n",
    "\n",
    "        # Group pass counts\n",
    "        pass_counts = df.groupby([\"Passer\", \"Recipient\"]).size().reset_index(name=\"Pass Count\")\n",
    "\n",
    "        # Calculate interaction metrics\n",
    "        interaction_data = []\n",
    "        for player in players:\n",
    "            row = {\"Player\": player}\n",
    "\n",
    "            row[\"Total Passes Made\"] = df[df[\"Passer\"] == player].shape[0]\n",
    "            row[\"Total Passes Received\"] = df[df[\"Recipient\"] == player].shape[0]\n",
    "\n",
    "            # Teammate pass interactions\n",
    "            teammates = [p for p in players if p != player]\n",
    "            for teammate in teammates:\n",
    "                count = pass_counts[\n",
    "                    (pass_counts[\"Passer\"] == player) &\n",
    "                    (pass_counts[\"Recipient\"] == teammate)\n",
    "                ][\"Pass Count\"].sum()\n",
    "                row[teammate] = count\n",
    "\n",
    "            interaction_data.append(row)\n",
    "\n",
    "        # Save to Excel\n",
    "        interaction_df = pd.DataFrame(interaction_data)\n",
    "        output_filename = file.replace(\".xlsx\", \"_interactions.xlsx\")\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        interaction_df.to_excel(output_path, index=False)\n",
    "\n",
    "        print(f\"Saved to: {os.path.abspath(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pass network graphs for all matches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 1_Arg_vs_Saudi_G1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harig\\AppData\\Local\\Temp\\ipykernel_7560\\3743411595.py:63: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network plot to: d:\\Masters\\hcnlp_project\\outputs\\pass_networks\\1_Arg_vs_Saudi_G1_network.png\n",
      "\n",
      "Processing: 2_Arg_vs_Mex_G2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harig\\AppData\\Local\\Temp\\ipykernel_7560\\3743411595.py:63: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network plot to: d:\\Masters\\hcnlp_project\\outputs\\pass_networks\\2_Arg_vs_Mex_G2_network.png\n",
      "\n",
      "Processing: 3_Arg_vs_Pol_G3.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harig\\AppData\\Local\\Temp\\ipykernel_7560\\3743411595.py:63: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network plot to: d:\\Masters\\hcnlp_project\\outputs\\pass_networks\\3_Arg_vs_Pol_G3_network.png\n",
      "\n",
      "Processing: 4_Arg_vs_Aus_R016.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harig\\AppData\\Local\\Temp\\ipykernel_7560\\3743411595.py:63: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network plot to: d:\\Masters\\hcnlp_project\\outputs\\pass_networks\\4_Arg_vs_Aus_R016_network.png\n",
      "\n",
      "Processing: 5_Arg_vs_Ned_QF.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harig\\AppData\\Local\\Temp\\ipykernel_7560\\3743411595.py:63: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network plot to: d:\\Masters\\hcnlp_project\\outputs\\pass_networks\\5_Arg_vs_Ned_QF_network.png\n",
      "\n",
      "Processing: 6_Arg_vs_Cro_SF.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harig\\AppData\\Local\\Temp\\ipykernel_7560\\3743411595.py:63: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network plot to: d:\\Masters\\hcnlp_project\\outputs\\pass_networks\\6_Arg_vs_Cro_SF_network.png\n",
      "\n",
      "Processing: 7_Arg_vs_Fra_Final.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harig\\AppData\\Local\\Temp\\ipykernel_7560\\3743411595.py:63: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network plot to: d:\\Masters\\hcnlp_project\\outputs\\pass_networks\\7_Arg_vs_Fra_Final_network.png\n",
      "\n",
      "Processing: arg_sau_passes.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harig\\AppData\\Local\\Temp\\ipykernel_7560\\3743411595.py:63: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network plot to: d:\\Masters\\hcnlp_project\\outputs\\pass_networks\\arg_sau_passes_network.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Input and output paths\n",
    "input_dir = os.path.join(\"..\", \"outputs\", \"pass_data\")\n",
    "output_dir = os.path.join(\"..\", \"outputs\", \"pass_networks\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over all Excel files\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        filepath = os.path.join(input_dir, file)\n",
    "        print(f\"\\nProcessing: {file}\")\n",
    "\n",
    "        # Load the pass data\n",
    "        df = pd.read_excel(filepath)\n",
    "\n",
    "        # Drop rows with missing essential data\n",
    "        df = df.dropna(subset=[\"Passer\", \"Recipient\", \"Start X\", \"Start Y\", \"End X\", \"End Y\"])\n",
    "\n",
    "        # Calculate average pass start locations for positioning\n",
    "        positions = df.groupby(\"Passer\")[[\"Start X\", \"Start Y\"]].mean()\n",
    "\n",
    "        # Count passes per player for sizing\n",
    "        pass_counts = df[\"Passer\"].value_counts()\n",
    "\n",
    "        # Unique players\n",
    "        all_players = set(df[\"Passer\"]).union(set(df[\"Recipient\"]))\n",
    "\n",
    "        # Create directed graph\n",
    "        G = nx.DiGraph()\n",
    "\n",
    "        # Add nodes\n",
    "        for player in all_players:\n",
    "            pos = tuple(positions.loc[player]) if player in positions.index else (50, 40)\n",
    "            size = pass_counts.get(player, 1)\n",
    "            G.add_node(player, pos=pos, size=size)\n",
    "\n",
    "        # Add edges with weights\n",
    "        edge_data = df.groupby([\"Passer\", \"Recipient\"]).size().reset_index(name=\"weight\")\n",
    "        for _, row in edge_data.iterrows():\n",
    "            G.add_edge(row[\"Passer\"], row[\"Recipient\"], weight=row[\"weight\"])\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        pos = nx.get_node_attributes(G, 'pos')\n",
    "        sizes = [G.nodes[n]['size'] * 10 for n in G.nodes]\n",
    "        weights = [G[u][v]['weight'] for u, v in G.edges]\n",
    "\n",
    "        nx.draw(G, pos, with_labels=True, arrows=True,\n",
    "                node_size=sizes,\n",
    "                width=weights,\n",
    "                edge_color=\"gray\",\n",
    "                node_color=\"skyblue\",\n",
    "                font_size=10,\n",
    "                connectionstyle='arc3,rad=0.1')\n",
    "\n",
    "        title = file.replace(\".xlsx\", \"\").replace(\"_\", \" \").title() + \" Passing Network\"\n",
    "        plt.title(title, fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        output_path = os.path.join(output_dir, file.replace(\".xlsx\", \"_network.png\"))\n",
    "        plt.savefig(output_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"Saved network plot to: {os.path.abspath(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics computation for all matches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player output directory: ..\\outputs\\player_metrics\n",
      "\n",
      "Processing: 1_Arg_vs_Saudi_G1.xlsx\n",
      "Saved player metrics to: d:\\Masters\\hcnlp_project\\outputs\\player_metrics\\1_Arg_vs_Saudi_G1_player_metrics.xlsx\n",
      "Saved graph metrics to: d:\\Masters\\hcnlp_project\\outputs\\graph_metrics\\1_Arg_vs_Saudi_G1_graph_metrics.csv\n",
      "\n",
      "Graph-Level Metrics:\n",
      "match: 1_Arg_vs_Saudi_G1\n",
      "num_nodes: 15\n",
      "num_edges: 131\n",
      "density: 0.6238095238095238\n",
      "avg_clustering: 0.7908276908276908\n",
      "\n",
      "Processing: 2_Arg_vs_Mex_G2.xlsx\n",
      "Saved player metrics to: d:\\Masters\\hcnlp_project\\outputs\\player_metrics\\2_Arg_vs_Mex_G2_player_metrics.xlsx\n",
      "Saved graph metrics to: d:\\Masters\\hcnlp_project\\outputs\\graph_metrics\\2_Arg_vs_Mex_G2_graph_metrics.csv\n",
      "\n",
      "Graph-Level Metrics:\n",
      "match: 2_Arg_vs_Mex_G2\n",
      "num_nodes: 16\n",
      "num_edges: 135\n",
      "density: 0.5625\n",
      "avg_clustering: 0.845770202020202\n",
      "\n",
      "Processing: 3_Arg_vs_Pol_G3.xlsx\n",
      "Saved player metrics to: d:\\Masters\\hcnlp_project\\outputs\\player_metrics\\3_Arg_vs_Pol_G3_player_metrics.xlsx\n",
      "Saved graph metrics to: d:\\Masters\\hcnlp_project\\outputs\\graph_metrics\\3_Arg_vs_Pol_G3_graph_metrics.csv\n",
      "\n",
      "Graph-Level Metrics:\n",
      "match: 3_Arg_vs_Pol_G3\n",
      "num_nodes: 16\n",
      "num_edges: 154\n",
      "density: 0.6416666666666667\n",
      "avg_clustering: 0.8302402458652458\n",
      "\n",
      "Processing: 4_Arg_vs_Aus_R016.xlsx\n",
      "Saved player metrics to: d:\\Masters\\hcnlp_project\\outputs\\player_metrics\\4_Arg_vs_Aus_R016_player_metrics.xlsx\n",
      "Saved graph metrics to: d:\\Masters\\hcnlp_project\\outputs\\graph_metrics\\4_Arg_vs_Aus_R016_graph_metrics.csv\n",
      "\n",
      "Graph-Level Metrics:\n",
      "match: 4_Arg_vs_Aus_R016\n",
      "num_nodes: 16\n",
      "num_edges: 143\n",
      "density: 0.5958333333333333\n",
      "avg_clustering: 0.820049395049395\n",
      "\n",
      "Processing: 5_Arg_vs_Ned_QF.xlsx\n",
      "Saved player metrics to: d:\\Masters\\hcnlp_project\\outputs\\player_metrics\\5_Arg_vs_Ned_QF_player_metrics.xlsx\n",
      "Saved graph metrics to: d:\\Masters\\hcnlp_project\\outputs\\graph_metrics\\5_Arg_vs_Ned_QF_graph_metrics.csv\n",
      "\n",
      "Graph-Level Metrics:\n",
      "match: 5_Arg_vs_Ned_QF\n",
      "num_nodes: 17\n",
      "num_edges: 156\n",
      "density: 0.5735294117647058\n",
      "avg_clustering: 0.7980367671544142\n",
      "\n",
      "Processing: 6_Arg_vs_Cro_SF.xlsx\n",
      "Saved player metrics to: d:\\Masters\\hcnlp_project\\outputs\\player_metrics\\6_Arg_vs_Cro_SF_player_metrics.xlsx\n",
      "Saved graph metrics to: d:\\Masters\\hcnlp_project\\outputs\\graph_metrics\\6_Arg_vs_Cro_SF_graph_metrics.csv\n",
      "\n",
      "Graph-Level Metrics:\n",
      "match: 6_Arg_vs_Cro_SF\n",
      "num_nodes: 16\n",
      "num_edges: 125\n",
      "density: 0.5208333333333334\n",
      "avg_clustering: 0.708364898989899\n",
      "\n",
      "Processing: 7_Arg_vs_Fra_Final.xlsx\n",
      "Saved player metrics to: d:\\Masters\\hcnlp_project\\outputs\\player_metrics\\7_Arg_vs_Fra_Final_player_metrics.xlsx\n",
      "Saved graph metrics to: d:\\Masters\\hcnlp_project\\outputs\\graph_metrics\\7_Arg_vs_Fra_Final_graph_metrics.csv\n",
      "\n",
      "Graph-Level Metrics:\n",
      "match: 7_Arg_vs_Fra_Final\n",
      "num_nodes: 17\n",
      "num_edges: 133\n",
      "density: 0.4889705882352941\n",
      "avg_clustering: 0.7243720331955626\n",
      "\n",
      "Processing: arg_sau_passes.xlsx\n",
      "Saved player metrics to: d:\\Masters\\hcnlp_project\\outputs\\player_metrics\\arg_sau_passes_player_metrics.xlsx\n",
      "Saved graph metrics to: d:\\Masters\\hcnlp_project\\outputs\\graph_metrics\\arg_sau_passes_graph_metrics.csv\n",
      "\n",
      "Graph-Level Metrics:\n",
      "match: arg_sau_passes\n",
      "num_nodes: 15\n",
      "num_edges: 131\n",
      "density: 0.6238095238095238\n",
      "avg_clustering: 0.7908276908276908\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "# Define input and output directories\n",
    "input_dir = os.path.join(\"..\", \"outputs\", \"pass_data\")\n",
    "player_output_dir = os.path.join(\"..\", \"outputs\", \"player_metrics\")\n",
    "print(f\"Player output directory: {player_output_dir}\")\n",
    "graph_output_dir = os.path.join(\"..\", \"outputs\", \"graph_metrics\")\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(player_output_dir, exist_ok=True)\n",
    "os.makedirs(graph_output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over all Excel files in the pass_data folder\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(input_dir, file)\n",
    "        print(f\"\\nProcessing: {file}\")\n",
    "\n",
    "        # Load the pass data from Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Remove rows with missing essential data\n",
    "        df = df.dropna(subset=[\"Passer\", \"Recipient\", \"Start X\", \"Start Y\", \"End X\", \"End Y\"])\n",
    "\n",
    "        # Create directed graph and add edges with pass weights\n",
    "        G = nx.DiGraph()\n",
    "        edges = df.groupby([\"Passer\", \"Recipient\"]).size().reset_index(name=\"weight\")\n",
    "        for _, row in edges.iterrows():\n",
    "            G.add_edge(row[\"Passer\"], row[\"Recipient\"], weight=row[\"weight\"])\n",
    "\n",
    "        # Compute node-level centrality metrics\n",
    "        metrics = {\n",
    "            \"degree_centrality\": nx.degree_centrality(G),\n",
    "            \"betweenness_centrality\": nx.betweenness_centrality(G),\n",
    "            \"closeness_centrality\": nx.closeness_centrality(G),\n",
    "            \"eigenvector_centrality\": nx.eigenvector_centrality(G, max_iter=500),\n",
    "            \"pagerank\": nx.pagerank(G),\n",
    "            \"clustering\": nx.clustering(G.to_undirected())\n",
    "        }\n",
    "\n",
    "        # Build a DataFrame with all player-level metrics\n",
    "        players = list(G.nodes())\n",
    "        player_metrics = pd.DataFrame({\"Player\": players})\n",
    "        for key, values in metrics.items():\n",
    "            player_metrics[key] = player_metrics[\"Player\"].map(values)\n",
    "\n",
    "        # Add pass volume stats\n",
    "        player_metrics[\"passes_made\"] = player_metrics[\"Player\"].apply(lambda p: G.out_degree(p, weight=\"weight\"))\n",
    "        player_metrics[\"passes_received\"] = player_metrics[\"Player\"].apply(lambda p: G.in_degree(p, weight=\"weight\"))\n",
    "\n",
    "        # Save player metrics to Excel\n",
    "        player_output_file_path = os.path.join(player_output_dir, file.replace(\".xlsx\", \"_player_metrics.xlsx\"))\n",
    "        player_metrics.to_excel(player_output_file_path, index=False)\n",
    "\n",
    "        print(f\"Saved player metrics to: {os.path.abspath(player_output_file_path)}\")\n",
    "\n",
    "        # Compute graph-level metrics\n",
    "        graph_metrics = {\n",
    "            \"match\": file.replace(\".xlsx\", \"\"),\n",
    "            \"num_nodes\": G.number_of_nodes(),\n",
    "            \"num_edges\": G.number_of_edges(),\n",
    "            \"density\": nx.density(G),\n",
    "            \"avg_clustering\": nx.average_clustering(G.to_undirected())\n",
    "        }\n",
    "\n",
    "        # Convert graph metrics to a DataFrame\n",
    "        graph_metrics_df = pd.DataFrame([graph_metrics])\n",
    "\n",
    "        # Save graph metrics to CSV\n",
    "        graph_output_file_path = os.path.join(graph_output_dir, file.replace(\".xlsx\", \"_graph_metrics.csv\"))\n",
    "        graph_metrics_df.to_csv(graph_output_file_path, index=False)\n",
    "\n",
    "        print(f\"Saved graph metrics to: {os.path.abspath(graph_output_file_path)}\")\n",
    "\n",
    "        # Print graph-level metrics for verification\n",
    "        print(\"\\nGraph-Level Metrics:\")\n",
    "        for key, val in graph_metrics.items():\n",
    "            print(f\"{key}: {val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q&A template based on previously computed metrics for players and matches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\outputs\\graph_metrics\\1_Arg_vs_Saudi_G1_graph_metrics.csv graph_file_path\n",
      "✅ Q&A file saved for 1 Arg vs Saudi Group Stage Match 1 as '..\\outputs\\pass_qa\\1 Arg vs Saudi Group Stage Match 1_QA.csv'\n",
      "..\\outputs\\graph_metrics\\2_Arg_vs_Mex_G2_graph_metrics.csv graph_file_path\n",
      "✅ Q&A file saved for 2 Arg vs Mex Group Stage Match 2 as '..\\outputs\\pass_qa\\2 Arg vs Mex Group Stage Match 2_QA.csv'\n",
      "..\\outputs\\graph_metrics\\3_Arg_vs_Pol_G3_graph_metrics.csv graph_file_path\n",
      "✅ Q&A file saved for 3 Arg vs Pol Group Stage Match 3 as '..\\outputs\\pass_qa\\3 Arg vs Pol Group Stage Match 3_QA.csv'\n",
      "..\\outputs\\graph_metrics\\4_Arg_vs_Aus_R016_graph_metrics.csv graph_file_path\n",
      "✅ Q&A file saved for 4 Arg vs Aus Round of 16 as '..\\outputs\\pass_qa\\4 Arg vs Aus Round of 16_QA.csv'\n",
      "..\\outputs\\graph_metrics\\5_Arg_vs_Ned_QF_graph_metrics.csv graph_file_path\n",
      "✅ Q&A file saved for 5 Arg vs Ned QF as '..\\outputs\\pass_qa\\5 Arg vs Ned QF_QA.csv'\n",
      "..\\outputs\\graph_metrics\\6_Arg_vs_Cro_SF_graph_metrics.csv graph_file_path\n",
      "✅ Q&A file saved for 6 Arg vs Cro SF as '..\\outputs\\pass_qa\\6 Arg vs Cro SF_QA.csv'\n",
      "..\\outputs\\graph_metrics\\7_Arg_vs_Fra_Final_graph_metrics.csv graph_file_path\n",
      "✅ Q&A file saved for 7 Arg vs Fra Final as '..\\outputs\\pass_qa\\7 Arg vs Fra Final_QA.csv'\n",
      "..\\outputs\\graph_metrics\\arg_sau_passes_graph_metrics.csv graph_file_path\n",
      "✅ Q&A file saved for arg sau passes as '..\\outputs\\pass_qa\\arg sau passes_QA.csv'\n"
     ]
    }
   ],
   "source": [
    "# Define input directories\n",
    "player_metrics_dir = os.path.join(\"..\", \"outputs\", \"player_metrics\")\n",
    "graph_metrics_dir = os.path.join(\"..\", \"outputs\", \"graph_metrics\")\n",
    "output_dir = os.path.join(\"..\", \"outputs\", \"pass_qa\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Helper: prettify match name\n",
    "def format_match_name(raw_name):\n",
    "    formatted = raw_name.replace(\"_\", \" \")\n",
    "    formatted = formatted.replace(\"G1\", \"Group Stage Match 1\")\n",
    "    formatted = formatted.replace(\"G2\", \"Group Stage Match 2\")\n",
    "    formatted = formatted.replace(\"G3\", \"Group Stage Match 3\")\n",
    "    formatted = formatted.replace(\"R016\", \"Round of 16\")\n",
    "    return formatted\n",
    "\n",
    "# Iterate over player metric files\n",
    "for player_file in os.listdir(player_metrics_dir):\n",
    "    if not player_file.endswith(\"_player_metrics.xlsx\"):\n",
    "        continue\n",
    "\n",
    "    player_file_path = os.path.join(player_metrics_dir, player_file)\n",
    "    match_id = player_file.replace(\"_player_metrics.xlsx\", \"\")\n",
    "    \n",
    "    graph_file = match_id + \"_graph_metrics.csv\"\n",
    "    graph_file_path = os.path.join(graph_metrics_dir, graph_file)\n",
    "    print(graph_file_path, 'graph_file_path')\n",
    "    \n",
    "    # Check existence before doing anything else\n",
    "    if not os.path.exists(graph_file_path):\n",
    "        print(f\"Warning: Graph file for {match_id} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Now we can safely format the match name for display\n",
    "    match_name = format_match_name(match_id)\n",
    "\n",
    "    # Load data\n",
    "    player_df = pd.read_excel(player_file_path).round(3)\n",
    "    graph_df = pd.read_csv(graph_file_path).round(3)\n",
    "\n",
    "    # Generate Q&A\n",
    "    qa_pairs = []\n",
    "\n",
    "    top_betweenness = player_df.sort_values(\"betweenness_centrality\", ascending=False).iloc[0]\n",
    "    qa_pairs.append({\n",
    "        \"question\": f\"Who had the highest betweenness centrality in the match against {match_name}?\",\n",
    "        \"answer\": f\"{top_betweenness['Player']} had the highest betweenness centrality with a value of {top_betweenness['betweenness_centrality']}.\"\n",
    "    })\n",
    "\n",
    "    top_eigen = player_df.sort_values(\"eigenvector_centrality\", ascending=False).iloc[0]\n",
    "    qa_pairs.append({\n",
    "        \"question\": f\"Which player was most influential based on eigenvector centrality in the match against {match_name}?\",\n",
    "        \"answer\": f\"{top_eigen['Player']} was the most influential player with an eigenvector centrality of {top_eigen['eigenvector_centrality']}.\"\n",
    "    })\n",
    "\n",
    "    top_passer = player_df.sort_values(\"passes_made\", ascending=False).iloc[0]\n",
    "    qa_pairs.append({\n",
    "        \"question\": f\"Who made the most passes for Argentina in the match against {match_name}?\",\n",
    "        \"answer\": f\"{top_passer['Player']} made the most passes, totaling {int(top_passer['passes_made'])}.\"\n",
    "    })\n",
    "\n",
    "    top_receiver = player_df.sort_values(\"passes_received\", ascending=False).iloc[0]\n",
    "    qa_pairs.append({\n",
    "        \"question\": f\"Who received the most passes for Argentina in the match against {match_name}?\",\n",
    "        \"answer\": f\"{top_receiver['Player']} received the most passes, totaling {int(top_receiver['passes_received'])}.\"\n",
    "    })\n",
    "\n",
    "    top_clust = player_df.sort_values(\"clustering\", ascending=False).iloc[0]\n",
    "    qa_pairs.append({\n",
    "        \"question\": f\"Which player was most involved in triangle passing patterns in the match against {match_name}?\",\n",
    "        \"answer\": f\"{top_clust['Player']} had the highest clustering coefficient of {top_clust['clustering']}.\"\n",
    "    })\n",
    "\n",
    "    density = graph_df[\"density\"].iloc[0]\n",
    "    qa_pairs.append({\n",
    "        \"question\": f\"What was the density of Argentina's pass network in the match against {match_name}?\",\n",
    "        \"answer\": f\"The network density was {density}, reflecting the overall connection of the team.\"\n",
    "    })\n",
    "\n",
    "    avg_clust = graph_df[\"avg_clustering\"].iloc[0]\n",
    "    qa_pairs.append({\n",
    "        \"question\": f\"What was the average clustering coefficient of Argentina's pass network in the match against {match_name}?\",\n",
    "        \"answer\": f\"The average clustering coefficient was {avg_clust}, indicating the level of tight triangle formations.\"\n",
    "    })\n",
    "\n",
    "    # Save\n",
    "    qa_df = pd.DataFrame(qa_pairs)\n",
    "    output_file_path = os.path.join(output_dir, f\"{match_name}_QA.csv\")\n",
    "    qa_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Q&A file saved for {match_name} as '{output_file_path}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
